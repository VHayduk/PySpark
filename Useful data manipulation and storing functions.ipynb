{"cells":[{"cell_type":"code","execution_count":null,"id":"2c0f3380-e671-4027-9041-386794c20993","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[],"source":["#Flatten JSON files\n","\n","def flatten(df):\n","   # compute Complex Fields (Lists and Structs) in Schema   \n","   complex_fields = dict([(field.name, field.dataType)\n","                             for field in df.schema.fields\n","                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n","   while len(complex_fields)!=0:\n","      col_name=list(complex_fields.keys())[0]\n","      print (\"Processing :\"+col_name+\" Type : \"+str(type(complex_fields[col_name])))\n","    \n","      # if StructType then convert all sub element to columns.\n","      # i.e. flatten structs\n","      if (type(complex_fields[col_name]) == StructType):\n","         expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]\n","         df=df.select(\"*\", *expanded).drop(col_name)\n","    \n","      # if ArrayType then add the Array Elements as Rows using the explode function\n","      # i.e. explode Arrays\n","      elif (type(complex_fields[col_name]) == ArrayType):    \n","         df=df.withColumn(col_name,explode_outer(col_name))\n","    \n","      # recompute remaining Complex Fields in Schema       \n","      complex_fields = dict([(field.name, field.dataType)\n","                             for field in df.schema.fields\n","                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n","   return df"]},{"cell_type":"code","execution_count":2,"id":"6b9c6928-4302-477e-ad0d-5873eacd1732","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-07-29T09:56:27.8137949Z","execution_start_time":"2024-07-29T09:56:27.5565443Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"47c1f18c-0157-45ec-a8f7-bbdf30e06491","queued_time":"2024-07-29T09:56:27.0266844Z","session_id":"aeccec2a-b75c-4a05-8abb-afe5b063ac9a","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":4,"statement_ids":[4]},"text/plain":["StatementMeta(, aeccec2a-b75c-4a05-8abb-afe5b063ac9a, 4, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Find latest date folder\n","\n","def find_latest_date_folder(directory_path):\n","    #List all folders in the directory\n","    folders = [f for f in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, f))]\n","\n","    # Folder names in YYYYMMDD format\n","    sorted_folders = sorted(folders, key=lambda x: int(x))\n","    \n","    # Sort for latest date folder\n","    latest_date_folder = sorted_folders[-1]\n","    \n","    return latest_date_folder"]},{"cell_type":"code","execution_count":null,"id":"e02965a5","metadata":{},"outputs":[],"source":["# OAuth 2.0 API request as a function \n","\n","def get_access_token():\n","    authorisation_endpoint = \"\"\n","\n","    params = {\n","        \"client_id\": \"\",\n","        \"scope\": \"\",\n","        \"redirect_uri\": \"\",\n","        \"response_type\": \"\"\n","    }\n","\n","    try:\n","        # HTTP GET request\n","        response = requests.get(authorisation_endpoint, params=params)\n","        response.raise_for_status()  # Raise an exception for HTTP errors\n","        code = response.content \n","    \n","    except requests.exceptions.RequestException as e:\n","        # Handle request exceptions such as network errors or invalid URLs\n","        print(\"Error making request:\", e)\n","\n","    # Token request\n","    # Token endpoint URL\n","    token_endpoint = \"\"\n","\n","    params = {\n","        \"grant_type\": \"\",\n","        \"scope\": \"\"\n","    }\n","\n","    headers = {\n","        \"Content-Type\": \"application/x-www-form-urlencoded\",\n","        \"Host\": \"\",\n","        \"Authorization\": \"Basic \" + credentials,\n","    }\n","\n","    # Send HTTP POST request\n","    response = requests.post(token_endpoint, data=params, headers=headers)\n","\n","    # Parse response JSON\n","    token_data = response.json()\n","\n","    return token_data.get(\"access_token\")"]},{"cell_type":"code","execution_count":null,"id":"89777775","metadata":{},"outputs":[],"source":["# Cleansing column names\n","# Function to remove spaces and capitalize the first letter of each word in column names\n","def camel_case(column_name):\n","    return ''.join(word.capitalize() for word in column_name.split())\n","\n","# Create new column names\n","new_column_names = [camel_case(c) for c in df.columns]\n","\n","# Rename columns\n","for old_name, new_name in zip(df.columns, new_column_names):\n","    df = df.withColumnRenamed(old_name, new_name)\n","\n","# Remove leading and trailing spaces\n","for column in df.columns:\n","        df = df.withColumn(column, trim(col(column)))"]},{"cell_type":"code","execution_count":null,"id":"392fda39","metadata":{},"outputs":[],"source":["# Gold layer testing fnction. Compare NULL and destinct values pro column: source vs after transformation (transformed)\n","def differences(source_table: DataFrame, transformed_table: DataFrame) -> DataFrame:\n","    def compute_counts(df: DataFrame, columns: list) -> DataFrame:\n","        results = []\n","        for field in columns:\n","            null_count = df.filter(col(field).isNull()).count()\n","            distinct_count = df.select(countDistinct(col(field))).collect()[0][0]\n","            results.append((field, null_count, distinct_count))\n","        return spark.createDataFrame(results, [\"Column\", \"NullCount\", \"DistinctCount\"])\n","\n","    # Compute counts for source table\n","    source_fields = source_table.columns\n","    source_results_df = compute_counts(source_table, source_fields)\n","\n","    # Compute counts for transformed table\n","    transformed_fields = transformed_table.columns\n","    transformed_results_df = compute_counts(transformed_table, transformed_fields) \\\n","        .withColumnRenamed(\"Column\", \"TransformedColumn\") \\\n","        .withColumnRenamed(\"NullCount\", \"TransformedNullCount\") \\\n","        .withColumnRenamed(\"DistinctCount\", \"TransformedDistinctCount\")\n","\n","    # Join and find differences\n","    differences_df = source_results_df.join(transformed_results_df, source_results_df.Column == transformed_results_df.TransformedColumn)\n","    differences_df = differences_df.filter(\n","        (col(\"DistinctCount\") != col(\"TransformedDistinctCount\")) | \n","        (col(\"NullCount\") != col(\"TransformedNullCount\"))\n","    )\n","    \n","    if differences_df.count() > 0:\n","        return differences_df\n","\n","    else:\n","        print(\"Sorce and transformed DataFrames match.\")\n","        return None\n","\n","## Example use case:\n","# Use differences(source, transformed) to retund a DataFrame where fields do not match\n","\n","#source = absenceevents  # Replace with actual DataFrame (source read in)\n","#transformed = cez_person_absence_events  # Replace with actual DataFrame (name of delta table out of source)\n","\n","#differences_df = differences(source, transformed)\n","#if differences_df is not None:\n","    #differences_df.show(100, truncate=False)"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"5f8e272f-beca-42e7-8d20-44754898253d","default_lakehouse_name":"Client_Testing","default_lakehouse_workspace_id":"fbf66f90-ea0a-49a4-a608-e722d08ef4e2","known_lakehouses":[{"id":"5f8e272f-beca-42e7-8d20-44754898253d"},{"id":"6ef3eb4e-9ad9-4086-95a2-b1edd79a8b8d"}]}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
